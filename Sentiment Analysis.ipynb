{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the companies to be analyzed as well as the time period to study have been chosen, we can move on to extracting the sentiment in each of the articles that mention them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA SETS\n",
    "\n",
    "    # FINANTIAL NEWS \n",
    "news = pd.read_csv(r\"C:\\Users\\user\\OneDrive - UvA\\Desktop\\UvAs\\Curso 4\\Scientific Data Analysis\\project\\Project_SDA\\data\\us_equities_news_dataset.csv\")\n",
    "\n",
    "    # TOP 7106 COMPANIES BY MARKET CAP\n",
    "market = pd.read_csv(r\"C:\\Users\\user\\OneDrive - UvA\\Desktop\\UvAs\\Curso 4\\Scientific Data Analysis\\project\\Project_SDA\\data\\companiesmarketcap.com - Companies ranked by Market Cap - CompaniesMarketCap.com.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED SELECTED COMPANIES\n",
    "ticker_list = ['AAPL','MSFT', 'BAC', 'AMZN', 'TSLA', 'XOM', 'JPM', 'KO', 'WMT','CVX', 'JNJ', 'HD', 'PG', 'MRK', 'PFE', 'LLY', 'NVDA', 'MA', 'UNH','V']\n",
    "companies_data = news[news['ticker'].isin(ticker_list)]\n",
    "companies_data = companies_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is the code that studies the content of each article in `news_data` and adds two rows to it: a sentiment score ranging from $-1$ to $1$ and a discrete version of this score with values $-1$, $0$ or $1$. The method used to perform this sentiment analysis is a dicionary based one from the Python package `nltk`. Although an alternative method using a pre-trained neural network was tested, the present method was $100$ times faster and resulted in an at least equally good performance. \n",
    "\n",
    "(To see/test the neural network alternative see two cells down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RULE-BASED/DICTIONARY SENTIMENT ANALYSIS\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "dic_method = SentimentIntensityAnalyzer()\n",
    "\n",
    "dic_sent_scores = []\n",
    "for article in companies_data.content:\n",
    "    dic_sent_scores.append(dic_method.polarity_scores(article)['compound'])\n",
    "\n",
    "    # ALSO ADD DISCRETE SCORE\n",
    "dic_sent_scores_dis = []\n",
    "for s in dic_sent_scores: dic_sent_scores_dis.append(1) if s>0 else  dic_sent_scores_dis.append(-1)\n",
    "\n",
    "companies_data['dic_sentiment'] = dic_sent_scores\n",
    "companies_data['dic_sentiment_dis'] = dic_sent_scores_dis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is a histogram showing the distribution of sentiments as well as a count of positive/negative articles in a discrete measures that shows that there are $5$ times more positive articles than there are negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/16894844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompanies_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dic_sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcompanies_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dic_sentiment_dis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(companies_data['dic_sentiment'],bins = 90)\n",
    "plt.show()\n",
    "companies_data['dic_sentiment_dis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-02 14:30:43,645 loading file C:\\Users\\user\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_17184/113076347.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  companies_data['ml_sentiment'] = ml_sent_scores\n"
     ]
    }
   ],
   "source": [
    "# B) PRE-TRAINED SENTIMENT CLASSIFIER\n",
    "# from flair.models import TextClassifier\n",
    "# from flair.data import Sentence\n",
    "\n",
    "# ml_method = TextClassifier.load('en-sentiment')\n",
    "\n",
    "# def get_sent(text):\n",
    "#     n_text = Sentence(text)\n",
    "#     ml_method.predict(n_text)\n",
    "#     if 'POSITIVE' in str(n_text.labels[0]):\n",
    "#         return 1\n",
    "#     elif 'NEGATIVE' in str(n_text.labels[0]):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# ml_sent_scores = []\n",
    "# for article in companies_data.content:\n",
    "#     ml_sent_scores.append(get_sent(article))\n",
    "\n",
    "# companies_data['ml_sentiment'] = ml_sent_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the resulting `news_data` with its new two sentiment columns to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('Data')\n",
    "companies_data.to_csv('news_select_companies_with_sent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "Evaluating different sentimen analysis packages: https://towardsdatascience.com/the-best-python-sentiment-analysis-package-1-huge-common-mistake-d6da9ad6cdeb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
